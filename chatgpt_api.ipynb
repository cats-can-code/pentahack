{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.3/70.3 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-win_amd64.whl (324 kB)\n",
      "     -------------------------------------- 324.5/324.5 kB 6.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp38-cp38-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.9/56.9 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\onedrive\\documents\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tqdm->openai) (0.4.5)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the purpose of the text?\n",
      "Answer: The purpose is to inform the reader about a specific topic or event.\n",
      "\n",
      "2. What does the text describe?\n",
      "Answer: The text describes a certain situation or issue.\n",
      "\n",
      "3. Who is the target audience for the text?\n",
      "Answer: The target audience may vary depending on the subject matter, but it could be anyone who is interested in the topic.\n",
      "\n",
      "4. What sources of information were used to write the text?\n",
      "Answer: The text may have used a variety of sources, such as research studies, interviews, or news articles.\n",
      "\n",
      "5. What is the main argument or point the text is trying to make?\n",
      "Answer: The main argument or point depends on the topic of the text.\n",
      "\n",
      "6. How is the information presented in the text?\n",
      "Answer: The information may be presented through various methods, such as through statistics, examples, or personal anecdotes.\n",
      "\n",
      "7. Is the text biased in any way?\n",
      "Answer: It depends on the author and their perspective on the topic.\n",
      "\n",
      "8. How does the text relate to current events or trends?\n",
      "Answer: The text may provide insight into current events or trends, or it may analyze them.\n",
      "\n",
      "9. What is the tone of the text?\n",
      "Answer: The tone may be informative, persuasive, or neutral.\n",
      "\n",
      "10. What is the significance of the topic discussed in the text?\n",
      "Answer: The significance of the topic may depend on its impact on society, economy, or individuals.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the purpose of automatic analysis of chart images? \n",
      "Answer: The purpose is to extract underlying data from them, which can bring benefits such as better analysis of related documents and automatic risk assessment. \n",
      "\n",
      "2. What are some challenges in data extraction from chart images? \n",
      "Answer: Challenges include the variety of chart styles, the lack of raw data when charts are published as images, and difficulty in scaling up rule-based methods. \n",
      "\n",
      "3. How does ChartOCR propose to extract data from multiple chart types? \n",
      "Answer: ChartOCR uses a hybrid framework that combines rule-based and deep learning methods and detects key points that define chart components, making extraction a uniform task. \n",
      "\n",
      "4. Why are rule-based methods sometimes inadequate for chart data extraction? \n",
      "Answer: The diversity of chart designs and styles make rule-based approaches difficult to scale, and they offer less control over intermediate results. \n",
      "\n",
      "5. How does ChartOCR compare to previous chart data extraction methods? \n",
      "Answer: ChartOCR achieves state-of-the-art performance with fast processing speeds on two public datasets, and introduces a large dataset for training deep models on chart images. \n",
      "\n",
      "6. What are some potential applications of chart data extraction? \n",
      "Answer: Applications include scientific document processing, visually-impaired accessibility, and question answering focused on querying chart images. \n",
      "\n",
      "7. What benefits can automatic chart data extraction bring to financial reporting processes? \n",
      "Answer: Automatic chart data extraction can enable automatic risk assessment and more efficient analysis of financial reports. \n",
      "\n",
      "8. What are some limitations of end-to-end deep neural network approaches for chart data extraction? \n",
      "Answer: These methods may not generalize well to all chart types and offer less control over intermediate data than rule-based methods. \n",
      "\n",
      "9. What is the purpose of key point detection methods in ChartOCR? \n",
      "Answer: Key point detection simplifies chart data extraction as a uniform task regardless of chart styles. \n",
      "\n",
      "10. Where is ChartOCR's code and dataset publicly available? \n",
      "Answer: ChartOCR's code and dataset are publicly available on GitHub at https://github.com/soap117/DeepRule.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fileObject = open(\"sample.txt\", \"r\")\n",
    "data = fileObject.read()\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"user\", \"content\": \"{data} \\n Using only information from the text above, generate 10 unique and truthful question and answer pairs on the main topics of the text using the format: \\n1.\\nQuestions:\\nAnswers:\\n2.\\nQuestions:\\nAnswers:\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": data + \" \\n Using only the information provided above and not using the general knowledge of chatgpt, make 10 unique and truthful question and answer pairs using the format:\\n1.\\nQuestions:\\nAnswers:\\n2.\\nQuestions:\\nAnswers:\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
